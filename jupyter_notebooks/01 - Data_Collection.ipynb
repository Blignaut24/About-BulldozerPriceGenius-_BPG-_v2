{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To acquire the \"Bluebook for Bulldozers\" dataset from a publicly accessible source, such as Kaggle or a direct download link.\n",
        "* To ensure the dataset is downloaded and stored securely within the project's directory structure.\n",
        "* To prepare the data for subsequent preprocessing and analysis steps.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* A stable internet connection for downloading the dataset.\n",
        "* Python libraries such as `requests`, `os`, `zipfile`, `shutil`, and `pathlib`.\n",
        "* A URL pointing to the compressed dataset file (e.g., a zip file).\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* The dataset in a compressed format (e.g., bluebook-for-bulldozers.zip) stored in the `data/raw` directory.\n",
        "* An unzipped version of the dataset in the `data/raw/bluebook-for-bulldozers` directory.\n",
        "* Relevant log messages and feedback confirming the dataset download and extraction status.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The Data Collection section primarily involves downloading and organizing the raw dataset before further processing.\n",
        "* Network connectivity and library installations should be verified before executing the code.\n",
        "* Any issues encountered during the download or extraction process may require checking the data source or network configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Execution Timestamp\n",
        "\n",
        "Purpose: This code block adds a timestamp to track notebook execution\n",
        "- Helps monitor when analysis was last performed\n",
        "- Ensures reproducibility of results\n",
        "- Useful for debugging and version control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook last run (end-to-end): 2025-02-14 16:36:02.190268\n"
          ]
        }
      ],
      "source": [
        "# Timestamp\n",
        "import datetime\n",
        "\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Directory Structure and Working Directory\n",
        "\n",
        "**Purpose: This code block establishes and explains the project organization**\n",
        "- Creates a standardized project structure for data science workflows\n",
        "- Documents the purpose of each directory for team collaboration\n",
        "- Gets current working directory for file path management\n",
        "\n",
        "## Key Components:\n",
        "1. `data/ directory` stores all datasets (raw, processed, interim)\n",
        "2. `src/` contains all source code (data preparation, models, utilities)\n",
        "3. `notebooks/` holds Jupyter notebooks for experimentation\n",
        "4. `results/` stores output files and visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "## Set Working Directory to Project Root\n",
        "**Purpose: Changes the current working directory to the parent directory**\n",
        "- Gets the folder one level above the current one\n",
        "- Makes sure all file locations work correctly throughout the project\n",
        "- Keeps files and folders organized in a clean way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "## Get Current Working Directory\n",
        "**Purpose: Retrieves and stores the current working directory path**\n",
        "- Gets the folder location where we're currently working\n",
        "- Saves this location in a variable called current_dir so we can use it later\n",
        "- Helps us find and work with files in the right place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Install Kaggle API Package\n",
        "**Purpose: Installs the Kaggle API client library version 1.5.12**\n",
        "- Enables programmatic access to Kaggle datasets and competitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle==1.5.12 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (1.17.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from kaggle==1.5.12) (2.3.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from requests->kaggle==1.5.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from requests->kaggle==1.5.12) (3.10)\n",
            "Requirement already satisfied: colorama in c:\\users\\blign\\dropbox\\1 project\\vs code project respository\\about-bulldozerpricegenius-_bpg-_v2\\env\\lib\\site-packages (from tqdm->kaggle==1.5.12) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle==1.5.12"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Kaggle API Authentication\n",
        "\n",
        "This code block sets up the Kaggle API authentication by:\n",
        "\n",
        "- Setting the Kaggle configuration directory to the current working directory\n",
        "- Adjusting file permissions for the kaggle.json credentials file based on the operating system:\n",
        "    - On Windows: Uses icacls to set appropriate file permissions\n",
        "    - On Unix/Linux/Mac: Sets file permissions to 600 (user read/write only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "# Set Kaggle config directory\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "\n",
        "# Check operating system and set permissions accordingly\n",
        "if platform.system() == 'Windows':\n",
        "    # Windows solution using Python's os module\n",
        "    import subprocess\n",
        "    subprocess.run(['icacls', 'kaggle.json', '/grant:r', f'{os.getenv(\"USERNAME\")}:F'], shell=True)\n",
        "else:\n",
        "    # Unix/Linux/Mac solution\n",
        "    os.chmod('kaggle.json', 0o600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downlaod Data Collection and Preprocessing Script\n",
        "This Python script downloads and organizes data about bulldozer prices. The script does these simple tasks:\n",
        "\n",
        "- Makes a new folder called 'data/raw' to store files\n",
        "- Gets a file from GitHub that contains bulldozer price information\n",
        "- Checks if the download worked correctly\n",
        "- Opens the downloaded file and removes any temporary files when done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download successful.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Create data/raw directory if it doesn't exist\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "# Define the zip file path\n",
        "zip_path = \"data/raw/bluebook-for-bulldozers.zip\"\n",
        "\n",
        "# Delete the zip file if it already exists\n",
        "if os.path.exists(zip_path):\n",
        "    os.remove(zip_path)\n",
        "\n",
        "# Download the file\n",
        "url = \"https://github.com/mrdbourke/zero-to-mastery-ml/raw/master/data/bluebook-for-bulldozers.zip\"\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(\"Download successful.\")\n",
        "else:\n",
        "    print(\"Download failed with status code:\", response.status_code)\n",
        "\n",
        "# Unzip the file if download was successful\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"data/raw\")\n",
        "    # Delete the zip file\n",
        "    os.remove(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Import and Preprocessing\n",
        "\n",
        "### Import Essential Data Science Libraries and Check Versions\n",
        "\n",
        "**Purpose: This code block imports fundamental Python libraries for data analysis and visualization**\n",
        "- `pandas:` For data manipulation and analysis\n",
        "- `numpy:` For numerical computations\n",
        "- `matplotlib:` For creating visualizations and plots\n",
        "\n",
        "**The version checks help ensure:**\n",
        "- *Code compatibility across different environments*\n",
        "- *Reproducibility of analysis*\n",
        "- *Easy debugging of version-specific issues*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas version: 2.2.3\n",
            "NumPy version: 2.2.2\n",
            "matplotlib version: 3.10.0\n"
          ]
        }
      ],
      "source": [
        "# Import data analysis tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(f\"pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"matplotlib version: {matplotlib.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Download and Setup\n",
        "\n",
        "This code block handles the automated download and setup of the bulldozer dataset. Here's what it does:\n",
        "\n",
        "- Creates a directory structure for storing the dataset using pathlib\n",
        "- Downloads the bulldozer dataset from GitHub if it doesn't exist locally\n",
        "- Extracts the downloaded zip file and organizes it in the proper directory\n",
        "- Cleans up temporary files after successful download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Dataset already exists!\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_dir = Path(\"data/raw/bluebook-for-bulldozers\")\n",
        "if not dataset_dir.is_dir():\n",
        "    print(\"[INFO] Downloading dataset...\")\n",
        "    \n",
        "    # Create directories\n",
        "    Path(\"data/raw\").mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download file\n",
        "    url = \"https://github.com/mrdbourke/zero-to-mastery-ml/raw/refs/heads/master/data/bluebook-for-bulldozers.zip\"\n",
        "    response = requests.get(url)\n",
        "    with open(\"dataset.zip\", \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    \n",
        "    # Unzip file\n",
        "    with zipfile.ZipFile(\"dataset.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    \n",
        "    # Move to correct location\n",
        "    shutil.move(\"bluebook-for-bulldozers\", \"data/raw/\")\n",
        "    \n",
        "    # Clean up zip file\n",
        "    os.remove(\"dataset.zip\")\n",
        "    \n",
        "    print(f\"[INFO] Dataset downloaded to {dataset_dir}\")\n",
        "else:\n",
        "    print(\"[INFO] Dataset already exists!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List Files and Folders\n",
        "\n",
        "**Purpose: Shows what files and folders are in our data folder**\n",
        "- Lists all the files and folders we have\n",
        "- Makes sure our data files are where they should be\n",
        "- Helps us check if everything downloaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Files/folders available in data\\raw\\bluebook-for-bulldozers:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Data Dictionary.xlsx',\n",
              " 'Machine_Appendix.csv',\n",
              " 'median_benchmark.csv',\n",
              " 'random_forest_benchmark_test.csv',\n",
              " 'Test.csv',\n",
              " 'test_predictions.csv',\n",
              " 'Train.7z',\n",
              " 'Train.csv',\n",
              " 'Train.zip',\n",
              " 'TrainAndValid.7z',\n",
              " 'TrainAndValid.csv',\n",
              " 'TrainAndValid.zip',\n",
              " 'train_tmp.csv',\n",
              " 'Valid.7z',\n",
              " 'Valid.csv',\n",
              " 'Valid.zip',\n",
              " 'ValidSolution.csv']"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(f\"[INFO] Files/folders available in {dataset_dir}:\")\n",
        "os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Training and Validation Dataset\n",
        "\n",
        "### Purpose\n",
        "This code loads our main data file that contains information about bulldozer sales, which we'll use to create a system that can predict bulldozer prices.\n",
        "\n",
        "### What it does\n",
        "- Opens and reads a file called `'TrainAndValid.csv'` that has information about bulldozer sales from the past\n",
        "- Uses a special tool called pandas to put all the data into an organized table called 'df'\n",
        "- Makes sure the computer can find and open the file from the right folder on your computer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Validation\n",
        "\n",
        "This code block handles the crucial task of loading our bulldozer dataset and includes error checking to ensure data availability. Here's what it does:\n",
        "\n",
        "- Imports necessary libraries (pandas for data handling, os for file operations)\n",
        "- Verifies the current working directory to ensure correct file paths\n",
        "- Sets up the file path to our bulldozer dataset\n",
        "- Includes error handling to check if the file exists before attempting to load it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\blign\\AppData\\Local\\Temp\\ipykernel_16232\\3367999310.py:12: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Print the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# Adjust the file path if necessary\n",
        "file_path = \"../data/raw/bluebook-for-bulldozers/TrainAndValid.csv\"\n",
        "\n",
        "# Check if the file exists at the specified path\n",
        "if os.path.exists(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"File loaded successfully.\")\n",
        "else:\n",
        "    print(f\"File not found at path: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading from Dropbox\n",
        "\n",
        "This code block handles loading our bulldozer dataset from a Dropbox location. Here's what it does:\n",
        "\n",
        "- Imports required libraries (os, pandas, pathlib) for file handling and data manipulation\n",
        "- Sets up the correct file path to our Dropbox folder where the dataset is stored\n",
        "- Uses Path for cross-platform compatibility (works on Windows, Mac, Linux)\n",
        "- Loads the TrainAndValid.csv file into a pandas DataFrame for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\blign\\AppData\\Local\\Temp\\ipykernel_16232\\2012957535.py:12: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the absolute path to your Dropbox folder\n",
        "dropbox_path = os.path.expanduser(\"~/Dropbox/1 PROJECT/VS Code Project Respository/About-BulldozerPriceGenius-_BPG-_v2\")\n",
        "\n",
        "# Create the full file path using Path for cross-platform compatibility\n",
        "file_path = Path(dropbox_path) / \"data\" / \"raw\" / \"bluebook-for-bulldozers\" / \"TrainAndValid.csv\"\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrame Information Display\n",
        "\n",
        "This code displays essential information about our DataFrame, including:\n",
        "\n",
        "- Total number of rows and columns\n",
        "- Column names and their data types\n",
        "- Memory usage\n",
        "- Number of non-null values per column\n",
        "This helps us understand our data structure and identify potential issues like missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 412698 entries, 0 to 412697\n",
            "Data columns (total 53 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   SalesID                   412698 non-null  int64  \n",
            " 1   SalePrice                 412698 non-null  float64\n",
            " 2   MachineID                 412698 non-null  int64  \n",
            " 3   ModelID                   412698 non-null  int64  \n",
            " 4   datasource                412698 non-null  int64  \n",
            " 5   auctioneerID              392562 non-null  float64\n",
            " 6   YearMade                  412698 non-null  int64  \n",
            " 7   MachineHoursCurrentMeter  147504 non-null  float64\n",
            " 8   UsageBand                 73670 non-null   object \n",
            " 9   saledate                  412698 non-null  object \n",
            " 10  fiModelDesc               412698 non-null  object \n",
            " 11  fiBaseModel               412698 non-null  object \n",
            " 12  fiSecondaryDesc           271971 non-null  object \n",
            " 13  fiModelSeries             58667 non-null   object \n",
            " 14  fiModelDescriptor         74816 non-null   object \n",
            " 15  ProductSize               196093 non-null  object \n",
            " 16  fiProductClassDesc        412698 non-null  object \n",
            " 17  state                     412698 non-null  object \n",
            " 18  ProductGroup              412698 non-null  object \n",
            " 19  ProductGroupDesc          412698 non-null  object \n",
            " 20  Drive_System              107087 non-null  object \n",
            " 21  Enclosure                 412364 non-null  object \n",
            " 22  Forks                     197715 non-null  object \n",
            " 23  Pad_Type                  81096 non-null   object \n",
            " 24  Ride_Control              152728 non-null  object \n",
            " 25  Stick                     81096 non-null   object \n",
            " 26  Transmission              188007 non-null  object \n",
            " 27  Turbocharged              81096 non-null   object \n",
            " 28  Blade_Extension           25983 non-null   object \n",
            " 29  Blade_Width               25983 non-null   object \n",
            " 30  Enclosure_Type            25983 non-null   object \n",
            " 31  Engine_Horsepower         25983 non-null   object \n",
            " 32  Hydraulics                330133 non-null  object \n",
            " 33  Pushblock                 25983 non-null   object \n",
            " 34  Ripper                    106945 non-null  object \n",
            " 35  Scarifier                 25994 non-null   object \n",
            " 36  Tip_Control               25983 non-null   object \n",
            " 37  Tire_Size                 97638 non-null   object \n",
            " 38  Coupler                   220679 non-null  object \n",
            " 39  Coupler_System            44974 non-null   object \n",
            " 40  Grouser_Tracks            44875 non-null   object \n",
            " 41  Hydraulics_Flow           44875 non-null   object \n",
            " 42  Track_Type                102193 non-null  object \n",
            " 43  Undercarriage_Pad_Width   102916 non-null  object \n",
            " 44  Stick_Length              102261 non-null  object \n",
            " 45  Thumb                     102332 non-null  object \n",
            " 46  Pattern_Changer           102261 non-null  object \n",
            " 47  Grouser_Type              102193 non-null  object \n",
            " 48  Backhoe_Mounting          80712 non-null   object \n",
            " 49  Blade_Type                81875 non-null   object \n",
            " 50  Travel_Controls           81877 non-null   object \n",
            " 51  Differential_Type         71564 non-null   object \n",
            " 52  Steering_Controls         71522 non-null   object \n",
            "dtypes: float64(3), int64(5), object(45)\n",
            "memory usage: 166.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# Get info about DataFrame\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "- We found that several things affect how much a used bulldozer sells for: how old it is, how many hours it has been used, and what type of bulldozer it is.\n",
        "- We also noticed that bulldozer prices go up and down depending on the time of year.\n",
        "- Our computer program can predict bulldozer prices fairly well, but we can still make it better.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Make the model better by adding more useful information and trying different ways to analyze the data.\n",
        "- Study how things like the economy and market demand affect bulldozer prices.\n",
        "- Improve how we collect data to make sure it's complete and accurate.\n",
        "- Try advanced methods like combining different models and fine-tuning settings to get better results.\n",
        "- Create an easy-to-use app or dashboard so people can easily access and use the price predictions."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
