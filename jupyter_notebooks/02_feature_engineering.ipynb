{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **02. Feature Engineering**\n",
        "*This notebook will focus on adding extra features like saleYear, saleMonth, etc., derived from the saledate column.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Execution Timestamp\n",
        "\n",
        "Purpose: This code block adds a timestamp to track notebook execution\n",
        "- Helps monitor when analysis was last performed\n",
        "- Ensures reproducibility of results\n",
        "- Useful for debugging and version control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook last run (end-to-end): 2025-02-15 11:24:36.324399\n"
          ]
        }
      ],
      "source": [
        "# Timestamp\n",
        "import datetime\n",
        "\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Project Directory Structure and Working Directory\n",
        "\n",
        "**Purpose: This code block establishes and explains the project organization**\n",
        "- Creates a standardized project structure for data science workflows\n",
        "- Documents the purpose of each directory for team collaboration\n",
        "- Gets current working directory for file path management\n",
        "\n",
        "## Key Components:\n",
        "1. `data/ directory` stores all datasets (raw, processed, interim)\n",
        "2. `src/` contains all source code (data preparation, models, utilities)\n",
        "3. `notebooks/` holds Jupyter notebooks for experimentation\n",
        "4. `results/` stores output files and visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up Working Directory\n",
        "This code block sets up the working environment by:\n",
        "- Changing to the project directory where our code and data files are located\n",
        "- Verifying the current working directory to ensure we're in the right place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository\\\\About-BulldozerPriceGenius-_BPG-_v2'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Move to the desired directory\n",
        "os.chdir('c:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository\\\\About-BulldozerPriceGenius-_BPG-_v2')\n",
        "\n",
        "# Get the current directory to verify the change\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Working Directory to Project Root\n",
        "**Purpose: Changes the current working directory to the parent directory**\n",
        "- Gets the folder one level above the current one\n",
        "- Makes sure all file locations work correctly throughout the project\n",
        "- Keeps files and folders organized in a clean way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "## Get Current Working Directory\n",
        "**Purpose: Retrieves and stores the current working directory path**\n",
        "- Gets the folder location where we're currently working\n",
        "- Saves this location in a variable called current_dir so we can use it later\n",
        "- Helps us find and work with files in the right place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir('c:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository')\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Import Essential Data Science Libraries and Check Versions**\n",
        "\n",
        "**Purpose: This code block imports fundamental Python libraries for data analysis and visualization**\n",
        "- `pandas:` For data manipulation and analysis\n",
        "- `numpy:` For numerical computations\n",
        "- `matplotlib:` For creating visualizations and plots\n",
        "\n",
        "**The version checks help ensure:**\n",
        "- *Code compatibility across different environments*\n",
        "- *Reproducibility of analysis*\n",
        "- *Easy debugging of version-specific issues*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas version: 2.2.3\n",
            "NumPy version: 2.2.2\n",
            "matplotlib version: 3.10.0\n"
          ]
        }
      ],
      "source": [
        "# Import data analysis tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(f\"pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"matplotlib version: {matplotlib.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# **1.3 Adding extra features to our DataFrame**\n",
        "### What is Feature Engineering?\n",
        "\n",
        "Feature engineering is a powerful technique that allows us to enhance our dataset by deriving new meaningful information from existing data. In this section, we'll explore how to extract valuable temporal features from our sale dates to improve our analysis.\n",
        "\n",
        "### Time-Based Components\n",
        "\n",
        "Our approach will focus on breaking down sale dates into multiple time-based components:\n",
        "\n",
        "- What year it was sold\n",
        "- What month it was sold\n",
        "- What day it was sold\n",
        "- What day of the week it was sold (like Monday = 1, Tuesday = 2)\n",
        "- What day of the year it was sold (like January 1st = 1, January 2nd = 2)\n",
        "\n",
        "### Data Safety\n",
        "\n",
        "To ensure data integrity throughout this process, we'll first create a backup of our original dataset. This precautionary step will allow us to revert any changes if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Creating a Safe Working Copy**\n",
        "Before we start modifying our dataset, it's crucial to create a backup copy. This ensures we can always return to our original data if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory: c:\\Users\\blign\\Dropbox\\1 PROJECT\\VS Code Project Respository\n",
            "Directories in the project:\n",
            "About-BulldozerPriceGenius-_BPG-_v2\n",
            "BulldozerPriceGenuis-BPG-\n",
            "churnometer\n",
            "CI-Malaria-Detection\n",
            "Culture-Project\n",
            "data\n",
            "housing-price-data-ml\n",
            "inputs\n",
            "job_board_django_ztm\n",
            "NederLearn\n",
            "NederLearn_V2\n",
            "Nederlearn_V3\n",
            "Nederlearn_V4\n",
            "NederLearn_V5\n",
            "PriceBulldozerAI\n",
            "Recipe-App\n",
            "Recipe-App-Tutorial\n",
            "Recipe-Tutorial-Dee-MC\n",
            "Scartch-Pad\n",
            "ZTM-Django-bitly-forms\n",
            "ztm_bd\n",
            "ztm_django_bitly_clone_project\n",
            "ztm_django_jobs_board\n",
            "ztm_django_movie_app\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Check the current directory\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current Directory: {current_directory}\")\n",
        "\n",
        "# List all directories in the project\n",
        "project_directory = current_directory  # Change this if your project directory is different\n",
        "directories = [d for d in os.listdir(project_directory) if os.path.isdir(os.path.join(project_directory, d))]\n",
        "\n",
        "print(\"Directories in the project:\")\n",
        "for directory in directories:\n",
        "    print(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File Path Verification Code\n",
        "\n",
        "This code block serves two essential purposes:\n",
        "\n",
        "- Verifies the existence of our training dataset (`TrainAndValid.csv`) before attempting to use it\n",
        "- Provides immediate feedback about file accessibility, helping prevent data loading errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The file C:\\Users\\blign\\Dropbox\\1 PROJECT\\VS Code Project Respository\\About-BulldozerPriceGenius-_BPG-_v2\\data\\raw\\bluebook-for-bulldozers\\TrainAndValid.csv exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"C:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository\\\\About-BulldozerPriceGenius-_BPG-_v2\\\\data\\\\raw\\\\bluebook-for-bulldozers\\\\TrainAndValid.csv\"\n",
        "\n",
        "# Check if file exists in specified path\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"The file {file_path} exists.\")\n",
        "else:\n",
        "    print(f\"The file {file_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Folder Path Verification\n",
        "\n",
        "This code block is designed to verify the existence of our processed data folder, which is crucial for data management and integrity. It performs two key functions:\n",
        "\n",
        "- Checks if the specified folder path exists in our project structure\n",
        "- Provides immediate feedback about folder accessibility to prevent data storage/retrieval errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder C:\\Users\\blign\\Dropbox\\1 PROJECT\\VS Code Project Respository\\About-BulldozerPriceGenius-_BPG-_v2\\data\\processed exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"C:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository\\\\About-BulldozerPriceGenius-_BPG-_v2\\\\data\\\\processed\"\n",
        "\n",
        "# Check if folder exists in specified path\n",
        "if os.path.exists(folder_path):\n",
        "    print(f\"The folder {folder_path} exists.\")\n",
        "else:\n",
        "    print(f\"The folder {folder_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and Preprocessing the Bulldozer Dataset\n",
        "\n",
        "This code block performs essential data loading and preprocessing steps:\n",
        "\n",
        "- Reads the raw bulldozer price dataset using pandas, with specific configurations:\n",
        "    - Disables low memory mode to handle mixed data types\n",
        "    - Automatically parses the 'saledate' column as datetime\n",
        "- Creates a safe working copy of the data to prevent modifications to the original dataset\n",
        "- Saves the preprocessed dataset to our processed data folder for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 412698 entries, 0 to 412697\n",
            "Data columns (total 53 columns):\n",
            " #   Column                    Non-Null Count   Dtype         \n",
            "---  ------                    --------------   -----         \n",
            " 0   SalesID                   412698 non-null  int64         \n",
            " 1   SalePrice                 412698 non-null  float64       \n",
            " 2   MachineID                 412698 non-null  int64         \n",
            " 3   ModelID                   412698 non-null  int64         \n",
            " 4   datasource                412698 non-null  int64         \n",
            " 5   auctioneerID              392562 non-null  float64       \n",
            " 6   YearMade                  412698 non-null  int64         \n",
            " 7   MachineHoursCurrentMeter  147504 non-null  float64       \n",
            " 8   UsageBand                 73670 non-null   object        \n",
            " 9   saledate                  412698 non-null  datetime64[ns]\n",
            " 10  fiModelDesc               412698 non-null  object        \n",
            " 11  fiBaseModel               412698 non-null  object        \n",
            " 12  fiSecondaryDesc           271971 non-null  object        \n",
            " 13  fiModelSeries             58667 non-null   object        \n",
            " 14  fiModelDescriptor         74816 non-null   object        \n",
            " 15  ProductSize               196093 non-null  object        \n",
            " 16  fiProductClassDesc        412698 non-null  object        \n",
            " 17  state                     412698 non-null  object        \n",
            " 18  ProductGroup              412698 non-null  object        \n",
            " 19  ProductGroupDesc          412698 non-null  object        \n",
            " 20  Drive_System              107087 non-null  object        \n",
            " 21  Enclosure                 412364 non-null  object        \n",
            " 22  Forks                     197715 non-null  object        \n",
            " 23  Pad_Type                  81096 non-null   object        \n",
            " 24  Ride_Control              152728 non-null  object        \n",
            " 25  Stick                     81096 non-null   object        \n",
            " 26  Transmission              188007 non-null  object        \n",
            " 27  Turbocharged              81096 non-null   object        \n",
            " 28  Blade_Extension           25983 non-null   object        \n",
            " 29  Blade_Width               25983 non-null   object        \n",
            " 30  Enclosure_Type            25983 non-null   object        \n",
            " 31  Engine_Horsepower         25983 non-null   object        \n",
            " 32  Hydraulics                330133 non-null  object        \n",
            " 33  Pushblock                 25983 non-null   object        \n",
            " 34  Ripper                    106945 non-null  object        \n",
            " 35  Scarifier                 25994 non-null   object        \n",
            " 36  Tip_Control               25983 non-null   object        \n",
            " 37  Tire_Size                 97638 non-null   object        \n",
            " 38  Coupler                   220679 non-null  object        \n",
            " 39  Coupler_System            44974 non-null   object        \n",
            " 40  Grouser_Tracks            44875 non-null   object        \n",
            " 41  Hydraulics_Flow           44875 non-null   object        \n",
            " 42  Track_Type                102193 non-null  object        \n",
            " 43  Undercarriage_Pad_Width   102916 non-null  object        \n",
            " 44  Stick_Length              102261 non-null  object        \n",
            " 45  Thumb                     102332 non-null  object        \n",
            " 46  Pattern_Changer           102261 non-null  object        \n",
            " 47  Grouser_Type              102193 non-null  object        \n",
            " 48  Backhoe_Mounting          80712 non-null   object        \n",
            " 49  Blade_Type                81875 non-null   object        \n",
            " 50  Travel_Controls           81877 non-null   object        \n",
            " 51  Differential_Type         71564 non-null   object        \n",
            " 52  Steering_Controls         71522 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(5), object(44)\n",
            "memory usage: 166.9+ MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ensure the file path is correct and the file exists at the specified location\n",
        "df = pd.read_csv(filepath_or_buffer=\"../data/raw/bluebook-for-bulldozers/TrainAndValid.csv\",\n",
        "                 low_memory=False, # set low_memory=False to prevent mixed data types warning \n",
        "                 parse_dates=[\"saledate\"]) # can use the parse_dates parameter and specify which column to treat as a date column\n",
        "\n",
        "# With parse_dates... check dtype of \"saledate\"\n",
        "df.info()\n",
        "# Make a copy of the original DataFrame to perform edits on\n",
        "df_tmp = df.copy()\n",
        "\n",
        "# Save the copy to the processed folder\n",
        "processed_file_path = \"C:\\\\Users\\\\blign\\\\Dropbox\\\\1 PROJECT\\\\VS Code Project Respository\\\\About-BulldozerPriceGenius-_BPG-_v2\\\\data\\\\processed\\\\TrainAndValid_processed.csv\"\n",
        "df_tmp.to_csv(processed_file_path, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 2 (2852421808.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    except Exception as e:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'try' statement on line 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
